{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie: Analiza i prognozowanie ceny kakao z użyciem LSTM\n",
    "\n",
    "## Cel zadania\n",
    "Zbudowanie modelu sieci neuronowej LSTM (Long Short-Term Memory) do przewidywania cen kakao na podstawie danych historycznych.\n",
    "\n",
    "## Dane wejściowe\n",
    "Plik: `Daily Prices_Home_NEW.csv` zawierający:\n",
    "- Date - data\n",
    "- London futures (£ sterling/tonne) - ceny kontraktów futures w Londynie\n",
    "- New York futures (US$/tonne) - ceny kontraktów futures w Nowym Jorku\n",
    "- ICCO daily price (US$/tonne) - dzienna cena ICCO w USD (użyjemy tej kolumny)\n",
    "- ICCO daily price (Euro/tonne) - dzienna cena ICCO w Euro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 1: Import bibliotek\n",
    "\n",
    "**Zadanie:** Zaimportuj niezbędne biblioteki:\n",
    "- `pandas` - do pracy z danymi tabelarycznymi\n",
    "- `numpy` - do operacji na tablicach numerycznych\n",
    "- `matplotlib.pyplot` - do wizualizacji\n",
    "- `MinMaxScaler` z `sklearn.preprocessing` - do normalizacji danych\n",
    "- `mean_squared_error, mean_absolute_error` z `sklearn.metrics` - do oceny modelu\n",
    "- `Sequential` z `tensorflow.keras.models` - do budowy modelu sekwencyjnego\n",
    "- `LSTM, Dense, Dropout` z `tensorflow.keras.layers` - warstwy sieci neuronowej\n",
    "- `warnings` - do wyłączenia ostrzeżeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zaimportuj wszystkie potrzebne biblioteki\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 2: Wczytanie i przygotowanie danych\n",
    "\n",
    "**Zadanie:** \n",
    "1. Wczytaj dane z pliku CSV używając `pd.read_csv()`\n",
    "2. Przekonwertuj kolumnę 'Date' na format datetime używając `pd.to_datetime()` z parametrem `format='%d/%m/%Y'`\n",
    "3. Posortuj DataFrame po dacie (od najstarszych) używając `.sort_values()` i zresetuj indeks\n",
    "4. Wyczyść dane w kolumnie 'ICCO daily price (US$/tonne)':\n",
    "   - Usuń przecinki używając `.str.replace(',', '')`\n",
    "   - Przekonwertuj na typ float używając `.astype(float)`\n",
    "5. Wyświetl zakres dat, liczbę rekordów i pierwsze wiersze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Wczytaj dane\n",
    "df = \n",
    "\n",
    "# TODO: Konwertuj kolumnę 'Date' na datetime\n",
    "\n",
    "\n",
    "# TODO: Posortuj DataFrame po dacie (od najstarszych)\n",
    "\n",
    "\n",
    "# TODO: Wyczyść dane - usuń przecinki i przekonwertuj na float\n",
    "\n",
    "\n",
    "# TODO: Wyświetl podstawowe informacje\n",
    "print(f\"Zakres dat: {df['Date'].min()} - {df['Date'].max()}\")\n",
    "print(f\"Liczba rekordów: {len(df)}\")\n",
    "print(f\"\\nPierwsze wiersze:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 3: Wizualizacja danych historycznych\n",
    "\n",
    "**Zadanie:**\n",
    "1. Stwórz wykres liniowy ceny kakao w czasie\n",
    "2. Ustaw rozmiar wykresu na (14, 6) używając `plt.figure(figsize=(14, 6))`\n",
    "3. Dodaj tytuł, etykiety osi, siatkę\n",
    "4. Obróć etykiety osi X o 45 stopni dla lepszej czytelności\n",
    "5. Wyświetl statystyki opisowe używając `.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stwórz wykres ceny kakao w czasie\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Wyświetl statystyki opisowe\n",
    "print(f\"\\nStatystyki opisowe:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 4: Przygotowanie danych dla LSTM\n",
    "\n",
    "**Zadanie:**\n",
    "1. Wybierz kolumnę z cenami i przekształć ją do kształtu (-1, 1) używając `.reshape(-1, 1)`\n",
    "2. Znormalizuj dane do zakresu [0, 1] używając `MinMaxScaler`:\n",
    "   - **Dlaczego normalizujemy?** Sieci neuronowe uczą się lepiej, gdy dane są w podobnej skali\n",
    "   - **feature_range=(0, 1)** - wszystkie wartości będą w przedziale [0, 1]\n",
    "3. Podziel dane na zbiór treningowy i testowy w proporcji 80/20:\n",
    "   - **80% treningowy** - model uczy się na tych danych\n",
    "   - **20% testowy** - sprawdzamy jak model radzi sobie z nieznanymi danymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Wybierz kolumnę z cenami i przekształć do kształtu (-1, 1)\n",
    "data = \n",
    "\n",
    "# TODO: Stwórz obiekt MinMaxScaler i znormalizuj dane\n",
    "scaler = \n",
    "data_scaled = \n",
    "\n",
    "# TODO: Podziel dane na zbiór treningowy (80%) i testowy (20%)\n",
    "train_size = \n",
    "train_data = \n",
    "test_data = \n",
    "\n",
    "print(f\"Rozmiar zbioru treningowego: {len(train_data)}\")\n",
    "print(f\"Rozmiar zbioru testowego: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 5: Tworzenie sekwencji dla LSTM\n",
    "\n",
    "**Zadanie:**\n",
    "1. Zdefiniuj funkcję `create_sequences(data, seq_length)`, która:\n",
    "   - Tworzy sekwencje danych o długości `seq_length`\n",
    "   - Zwraca X (dane wejściowe) i y (wartości docelowe)\n",
    "   - **Przykład:** dla seq_length=30, model używa 30 dni wstecz do przewidzenia dnia następnego\n",
    "\n",
    "2. Ustaw **SEQ_LENGTH = 30** (liczba dni wykorzystywanych do predykcji)\n",
    "   - **Dlaczego 30?** To kompromis między:\n",
    "     - Za mało: model ma za mało kontekstu\n",
    "     - Za dużo: model może się przeuczyć i będzie wolniejszy\n",
    "\n",
    "3. Stwórz sekwencje dla danych treningowych i testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zdefiniuj funkcję do tworzenia sekwencji\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    # TODO: Uzupełnij pętlę, która tworzy sekwencje\n",
    "    for i in range(len(data) - seq_length):\n",
    "        # Dodaj sekwencję do X\n",
    "        \n",
    "        # Dodaj wartość docelową do y\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# TODO: Ustaw długość sekwencji\n",
    "SEQ_LENGTH = \n",
    "\n",
    "# TODO: Stwórz sekwencje dla zbioru treningowego i testowego\n",
    "X_train, y_train = \n",
    "X_test, y_test = \n",
    "\n",
    "print(f\"Kształt X_train: {X_train.shape}\")\n",
    "print(f\"Kształt y_train: {y_train.shape}\")\n",
    "print(f\"Kształt X_test: {X_test.shape}\")\n",
    "print(f\"Kształt y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 6: Budowa modelu LSTM\n",
    "\n",
    "**Zadanie:** Zbuduj model Sequential z następującymi warstwami:\n",
    "\n",
    "### Parametry warstw:\n",
    "\n",
    "1. **LSTM(64, return_sequences=True, input_shape=(SEQ_LENGTH, 1))**\n",
    "   - **64** - liczba jednostek LSTM (neuronów) w warstwie\n",
    "   - **return_sequences=True** - zwraca pełną sekwencję (potrzebne dla kolejnej warstwy LSTM)\n",
    "   - **input_shape=(SEQ_LENGTH, 1)** - kształt danych wejściowych (30 kroków czasowych, 1 cecha)\n",
    "\n",
    "2. **Dropout(0.2)**\n",
    "   - **0.2** - wyłącza losowo 20% neuronów podczas treningu\n",
    "   - **Cel:** zapobieganie przeuczeniu (overfitting)\n",
    "\n",
    "3. **LSTM(32, return_sequences=False)**\n",
    "   - **32** - mniej neuronów niż w pierwszej warstwie\n",
    "   - **return_sequences=False** - zwraca tylko ostatni wynik (nie potrzebujemy sekwencji)\n",
    "\n",
    "4. **Dropout(0.2)**\n",
    "\n",
    "5. **Dense(16, activation='relu')**\n",
    "   - **16** - liczba neuronów w warstwie gęstej\n",
    "   - **activation='relu'** - funkcja aktywacji ReLU (Rectified Linear Unit)\n",
    "\n",
    "6. **Dense(1)**\n",
    "   - **1** - warstwa wyjściowa z jednym neuronem (przewidywana cena)\n",
    "\n",
    "### Kompilacja modelu:\n",
    "- **optimizer='adam'** - algorytm optymalizacji Adam (adaptacyjne tempo uczenia)\n",
    "- **loss='mse'** - funkcja straty Mean Squared Error\n",
    "- **metrics=['mae']** - dodatkowa metryka Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zbuduj model LSTM\n",
    "model = Sequential([\n",
    "    # TODO: Dodaj pierwszą warstwę LSTM z 64 neuronami\n",
    "    \n",
    "    # TODO: Dodaj Dropout(0.2)\n",
    "    \n",
    "    # TODO: Dodaj drugą warstwę LSTM z 32 neuronami\n",
    "    \n",
    "    # TODO: Dodaj Dropout(0.2)\n",
    "    \n",
    "    # TODO: Dodaj warstwę Dense z 16 neuronami i aktywacją 'relu'\n",
    "    \n",
    "    # TODO: Dodaj warstwę wyjściową Dense z 1 neuronem\n",
    "    \n",
    "])\n",
    "\n",
    "# TODO: Skompiluj model z optimizer='adam', loss='mse', metrics=['mae']\n",
    "\n",
    "\n",
    "# Wyświetl podsumowanie modelu\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 7: Trenowanie modelu\n",
    "\n",
    "**Zadanie:** Wytrenuj model używając metody `.fit()`\n",
    "\n",
    "### Parametry treningu:\n",
    "- **epochs=50** - liczba pełnych przejść przez zbiór treningowy\n",
    "  - Więcej epok = dłuższe uczenie, ale lepsze dopasowanie\n",
    "  - Za dużo epok = ryzyko przeuczenia\n",
    "  \n",
    "- **batch_size=16** - liczba próbek przetwarzanych przed aktualizacją wag\n",
    "  - Mniejszy batch = więcej aktualizacji, ale bardziej \"hałaśliwe\" uczenie\n",
    "  - Większy batch = stabilniejsze uczenie, ale może utknąć w minimum lokalnym\n",
    "  \n",
    "- **validation_split=0.1** - 10% danych treningowych użytych do walidacji\n",
    "  - Pozwala monitorować czy model się nie przeuczy\n",
    "  \n",
    "- **verbose=1** - wyświetla pasek postępu podczas treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Wytrenuj model\n",
    "history = model.fit(\n",
    "    # TODO: Dodaj dane treningowe X_train, y_train\n",
    "    \n",
    "    # TODO: Ustaw liczbę epok na 50\n",
    "    \n",
    "    # TODO: Ustaw batch_size na 16\n",
    "    \n",
    "    # TODO: Ustaw validation_split na 0.1\n",
    "    \n",
    "    # TODO: Ustaw verbose na 1\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 8: Wizualizacja procesu uczenia\n",
    "\n",
    "**Zadanie:** Stwórz dwa wykresy pokazujące:\n",
    "1. Funkcję straty (Loss) dla zbioru treningowego i walidacyjnego\n",
    "2. Metrykę MAE dla zbioru treningowego i walidacyjnego\n",
    "\n",
    "**Wskazówka:** Użyj `history.history['loss']`, `history.history['val_loss']`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stwórz figurę z dwoma wykresami obok siebie\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# TODO: Pierwszy wykres - funkcja straty\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Drugi wykres - MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 9: Predykcje i ewaluacja modelu\n",
    "\n",
    "**Zadanie:**\n",
    "1. Wykonaj predykcje na zbiorze testowym używając `model.predict()`\n",
    "2. Odwróć normalizację predykcji i prawdziwych wartości używając `scaler.inverse_transform()`\n",
    "3. Oblicz metryki:\n",
    "   - **MSE** (Mean Squared Error) - średni kwadrat błędu\n",
    "   - **RMSE** (Root MSE) - pierwiastek z MSE, w tych samych jednostkach co cena\n",
    "   - **MAE** (Mean Absolute Error) - średni błąd bezwzględny\n",
    "   - **MAPE** (Mean Absolute Percentage Error) - średni procentowy błąd bezwzględny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Wykonaj predykcje na zbiorze testowym\n",
    "predictions = \n",
    "\n",
    "# TODO: Odwróć normalizację\n",
    "predictions_rescaled = \n",
    "y_test_rescaled = \n",
    "\n",
    "# TODO: Oblicz metryki\n",
    "mse = \n",
    "rmse = \n",
    "mae = \n",
    "mape = \n",
    "\n",
    "print(f\"Metryki modelu:\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f} US$/tonne\")\n",
    "print(f\"MAE: {mae:.2f} US$/tonne\")\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 10: Wizualizacja predykcji vs rzeczywiste wartości\n",
    "\n",
    "**Zadanie:** Stwórz wykres liniowy porównujący:\n",
    "- Rzeczywiste ceny (z y_test_rescaled)\n",
    "- Predykcje modelu (z predictions_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stwórz wykres porównujący predykcje z rzeczywistymi wartościami\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 11: Wykres rozrzutu (scatter plot)\n",
    "\n",
    "**Zadanie:** Stwórz wykres rozrzutu pokazujący:\n",
    "- Oś X: rzeczywiste wartości\n",
    "- Oś Y: przewidywane wartości\n",
    "- Czerwona linia: idealna predykcja (y=x)\n",
    "\n",
    "**Interpretacja:** Im bliżej punkty są do czerwonej linii, tym lepszy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stwórz wykres rozrzutu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 12: Predykcja przyszłych wartości\n",
    "\n",
    "**Zadanie:**\n",
    "1. Zdefiniuj funkcję `predict_next_days()`, która:\n",
    "   - Bierze model, ostatnią sekwencję, liczbę dni do przewidzenia i scaler\n",
    "   - W pętli:\n",
    "     - Przewiduje następny dzień\n",
    "     - Aktualizuje sekwencję (usuwa pierwszy element, dodaje przewidywaną wartość)\n",
    "   - Zwraca przewidziane ceny po odwróceniu normalizacji\n",
    "\n",
    "2. Przewidź ceny na 14 dni w przód"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Zdefiniuj funkcję do przewidywania przyszłych dni\n",
    "def predict_next_days(model, last_sequence, n_days, scaler):\n",
    "    predictions = []\n",
    "    current_sequence = last_sequence.copy()\n",
    "    \n",
    "    # TODO: Uzupełnij pętlę przewidującą kolejne dni\n",
    "    for _ in range(n_days):\n",
    "        # Przewidź następny dzień\n",
    "        \n",
    "        \n",
    "        # Zaktualizuj sekwencję\n",
    "        \n",
    "    \n",
    "    # TODO: Odwróć normalizację\n",
    "    predictions = \n",
    "    return predictions\n",
    "\n",
    "# TODO: Pobierz ostatnią sekwencję z danych\n",
    "last_sequence = \n",
    "\n",
    "# TODO: Przewiduj na 14 dni w przód\n",
    "future_days = 14\n",
    "future_predictions = \n",
    "\n",
    "print(f\"\\nPredykcje na kolejne {future_days} dni:\")\n",
    "for i, pred in enumerate(future_predictions, 1):\n",
    "    print(f\"Dzień +{i}: {pred[0]:.2f} US$/tonne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Krok 13: Wizualizacja predykcji przyszłych wartości\n",
    "\n",
    "**Zadanie:** Stwórz wykres pokazujący:\n",
    "- Niebieską linię: ostatnie 30 dni danych historycznych\n",
    "- Czerwoną linię przerywaną: 14 dni predykcji\n",
    "- Zieloną linię pionową: dzień dzisiejszy (granica między danymi a predykcją)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Pobierz ostatnie 30 dni\n",
    "last_30_days = \n",
    "all_values = np.concatenate([last_30_days, future_predictions])\n",
    "\n",
    "# TODO: Stwórz wykres z danymi historycznymi i predykcjami\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Dane historyczne\n",
    "\n",
    "\n",
    "# Predykcje\n",
    "\n",
    "\n",
    "# Linia \"dziś\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Zadania dodatkowe (dla ambitnych!)\n",
    "\n",
    "1. **Eksperymentuj z parametrami:**\n",
    "   - Zmień SEQ_LENGTH (np. 10, 60, 90) i zobacz jak wpływa to na wyniki\n",
    "   - Zmień liczbę neuronów w warstwach LSTM (np. 128, 64, 32)\n",
    "   - Zmień liczbę epok (np. 30, 100, 200)\n",
    "   - Zmień batch_size (np. 8, 32, 64)\n",
    "\n",
    "2. **Dodaj więcej warstw:**\n",
    "   - Spróbuj dodać trzecią warstwę LSTM\n",
    "   - Dodaj więcej warstw Dense\n",
    "\n",
    "3. **Użyj innych kolumn:**\n",
    "   - Spróbuj użyć ceny z Londynu lub Nowego Jorku\n",
    "   - Użyj wielu kolumn jednocześnie (multi-feature LSTM)\n",
    "\n",
    "4. **Zapisz i wczytaj model:**\n",
    "   - Użyj `model.save('cocoa_model.h5')` do zapisania\n",
    "   - Użyj `load_model('cocoa_model.h5')` do wczytania\n",
    "\n",
    "5. **Porównaj z innymi metodami:**\n",
    "   - Zbuduj prosty model używając GRU zamiast LSTM\n",
    "   - Spróbuj użyć prostszego modelu (np. Linear Regression) jako baseline\n",
    "\n",
    "---\n",
    "\n",
    "## Podsumowanie\n",
    "\n",
    "Gratulacje! Po wykonaniu wszystkich kroków powinieneś mieć:\n",
    "- Działający model LSTM do przewidywania cen kakao\n",
    "- Wizualizacje pokazujące jak dobrze model działa\n",
    "- Predykcje na przyszłość\n",
    "- Zrozumienie parametrów i architektury sieci LSTM\n",
    "\n",
    "### Kluczowe wnioski:\n",
    "- LSTM dobrze radzi sobie z danymi sekwencyjnymi (szeregi czasowe)\n",
    "- Normalizacja danych jest kluczowa dla wydajności sieci neuronowych\n",
    "- Dropout pomaga zapobiegać przeuczeniu\n",
    "- Podział na zbiór treningowy/testowy/walidacyjny pozwala ocenić model\n",
    "- Predykcja przyszłych wartości bazuje na ostatnich znanych danych"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
